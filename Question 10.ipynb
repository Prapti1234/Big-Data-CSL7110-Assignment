{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc2f5ca-1938-47c9-9666-b565aaa2c93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/02/10 11:39:05 WARN Utils: Your hostname, DESKTOP-M0J6OKT resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "26/02/10 11:39:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/10 11:39:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.255.255.254:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>GutenbergAnalysis</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd4e56af3b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"GutenbergAnalysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e79dcd8a-f293-463e-abfc-70d05e5a1176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "4119082"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import input_file_name\n",
    "\n",
    "books_df = spark.read.text(\"/home/prapti/CSL7110_Assignment/Hadoop/Dataset/*.txt\") \\\n",
    "    .withColumn(\"file_name\", input_file_name()) \\\n",
    "    .withColumnRenamed(\"value\", \"text\")\n",
    "\n",
    "books_df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f2fbb6e-9c0c-47d2-8ff4-315462db7a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "425"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_list, concat_ws\n",
    "\n",
    "books_full = books_df.groupBy(\"file_name\") \\\n",
    "    .agg(concat_ws(\"\\n\", collect_list(\"text\")).alias(\"text\"))\n",
    "\n",
    "books_full.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54ad533c-e5ee-4765-91cf-2fda92bdabff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------+---------------------------+------------------------+--------+--------+\n",
      "|file_name                                                    |title                      |release_date            |language|encoding|\n",
      "+-------------------------------------------------------------+---------------------------+------------------------+--------+--------+\n",
      "|file:///home/prapti/CSL7110_Assignment/Hadoop/Dataset/22.txt |Roget's Thesaurus          |December, 1991          |English |ASCII   |\n",
      "|file:///home/prapti/CSL7110_Assignment/Hadoop/Dataset/351.txt|Of Human Bondage           |May 6, 2008 [EBook #351]|English |ASCII   |\n",
      "|file:///home/prapti/CSL7110_Assignment/Hadoop/Dataset/87.txt |The 1993 CIA World Factbook|October, 1993           |English |ASCII   |\n",
      "|file:///home/prapti/CSL7110_Assignment/Hadoop/Dataset/349.txt|The Harvester              |October, 1995           |English |ASCII   |\n",
      "|file:///home/prapti/CSL7110_Assignment/Hadoop/Dataset/233.txt|Sister Carrie              |March, 1995             |English |ASCII   |\n",
      "+-------------------------------------------------------------+---------------------------+------------------------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "\n",
    "books_meta = books_full \\\n",
    "    .withColumn(\"title\", regexp_extract(\"text\", r\"Title:\\s*(.*)\", 1)) \\\n",
    "    .withColumn(\"release_date\", regexp_extract(\"text\", r\"Release Date:\\s*(.*)\", 1)) \\\n",
    "    .withColumn(\"language\", regexp_extract(\"text\", r\"Language:\\s*(.*)\", 1)) \\\n",
    "    .withColumn(\"encoding\", regexp_extract(\"text\", r\"Character set encoding:\\s*(.*)\", 1))\n",
    "\n",
    "books_meta.select(\"file_name\", \"title\", \"release_date\", \"language\", \"encoding\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da36eb5f-6019-4d2a-9681-1e809a719c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:====================================================>   (14 + 1) / 15]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+----+\n",
      "|release_date            |year|\n",
      "+------------------------+----+\n",
      "|December, 1991          |1991|\n",
      "|May 6, 2008 [EBook #351]|2008|\n",
      "|October, 1993           |1993|\n",
      "|October, 1995           |1995|\n",
      "|March, 1995             |1995|\n",
      "+------------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "\n",
    "books_meta = books_meta.withColumn(\n",
    "    \"year\",\n",
    "    regexp_extract(\"release_date\", r\"(\\d{4})\", 1)\n",
    ")\n",
    "\n",
    "books_meta.select(\"release_date\", \"year\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be68f3e8-b3b7-4fed-975f-b4e8f5bf6226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:===================================================>      (8 + 1) / 9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|    |   17|\n",
      "|1975|    1|\n",
      "|1978|    1|\n",
      "|1979|    1|\n",
      "|1991|    7|\n",
      "|1992|   19|\n",
      "|1993|   13|\n",
      "|1994|   17|\n",
      "|1995|   60|\n",
      "|1996|   53|\n",
      "+----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "books_meta.groupBy(\"year\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"year\") \\\n",
    "    .show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed99ef69-0bbe-4744-b35d-fd5c19c5b04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:====================================================>   (14 + 1) / 15]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|language|count|\n",
      "+--------+-----+\n",
      "| English|  404|\n",
      "|        |   15|\n",
      "|   Latin|    6|\n",
      "+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "books_meta.groupBy(\"language\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"count\", ascending=False) \\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77adcad8-4d1f-4269-bf97-8912aba831c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:====================================================>   (14 + 1) / 15]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|average_title_length|\n",
      "+--------------------+\n",
      "|  22.023529411764706|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import length, avg\n",
    "\n",
    "books_meta.select(avg(length(\"title\")).alias(\"average_title_length\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9874160a-8638-4d24-a66c-e4e90657c579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
